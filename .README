# Voice-AI Agent (main.py)

A FastAPI service that bridges Twilio Media Streams ↔ OpenAI Realtime API, with Pinecone for Q&A and N8N for appointment booking.

## Table of Contents

1. [Overview](#overview)  
2. [Prerequisites](#prerequisites)  
3. [Installation](#installation)  
4. [Configuration](#configuration)  
5. [Running Locally](#running-locally)  
6. [Architecture](#architecture)  
7. [Endpoints](#endpoints)  
8. [Example Flow](#example-flow)  
9. [Testing](#testing)  
10. [Deployment](#deployment)  
11. [Troubleshooting](#troubleshooting)  
12. [Next Steps](#next-steps)  

## Overview

Build a real-time voice AI agent using FastAPI that receives Twilio audio, forwards it to OpenAI's realtime speech-to-speech API, and handles two LLM-driven tools (QA via Pinecone + booking via N8N).

## Prerequisites

- Python 3.10 or higher  
- Twilio account with Media Streams enabled  
- OpenAI API access to Realtime speech models (e.g. `gpt-4o-realtime-preview`)  
- Pinecone account with an index and assistant set up  
- N8N instance with two workflows:  
  - **Route 1**: fetch chat history and summary  
  - **Route 3**: check/create calendar bookings  
- A publicly accessible URL for your FastAPI service (e.g. via ngrok or cloud deployment)  

## Installation

```bash
git clone <repo-url>
cd <repo-directory>
pip install -r requirements.txt

Configuration

Copy the example environment file and fill in your credentials:
cp .env.example .env
Edit .env and set:
OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key
N8N_WEBHOOK_URL=https://your-n8n-instance/webhook
REPL_PUBLIC_URL=https://your-service-url
PORT=8000
Running Locally

Start the server with Uvicorn:

uvicorn src.main:app --reload --host 0.0.0.0 --port $PORT
Architecture

Configuration & Initialization
Loads environment variables (OpenAI, Pinecone, N8N, public URL)
Defines a session store to track ongoing calls
/incoming-call Endpoint
HTTP POST from Twilio contains form data (e.g. From)
Fetches prior chat history via N8N (route 1) to customize the first message
Seeds a session and responds with TwiML <Connect><Stream> XML, pointing to /media-stream, including sessionId, firstMessage, and callerNumber
/media-stream WebSocket Handler
Accepts a WebSocket connection from Twilio Media Streams
Reads the initial JSON handshake to obtain sessionId
Opens a WebSocket client connection to the OpenAI Realtime API with the realtime=v1 beta header
Sends a session.update event defining:
Audio formats (g711_ulaw), server VAD, voice model (shimmer)
System instructions prompt
Modalities (text + audio)
Temperature
Function schemas for:
question_and_answer(question: string)
schedule_meeting(name: string, email: string, purpose: string, datetime: string, location: string)
Bidirectional Relay Loop
Twilio → App → OpenAI
Receives Twilio "media" events with audio payloads, forwards as input.audio messages to OpenAI
OpenAI → App → Twilio
Streams back response.audio.delta frames, forwarded as Twilio "media" events so the caller hears the agent in near-real time
Function Calls
OpenAI signals response.function_call_arguments.done when calling a tool; the app dispatches accordingly
Function Call Dispatcher
question_and_answer
Uses Pinecone Assistant SDK to query a knowledge base, streams chunks into a full answer string
Returns the answer via function_call_output and a final response.create
schedule_meeting
Maps location to a calendar ID
Posts meeting details to N8N (route 3) to check availability or create an event
Returns confirmation or alternative times via LLM response
Helper Utilities
send_to_n8n() abstracts POST calls to N8N, ideally using an async HTTP client (httpx.AsyncClient)
Error Handling & Timeouts
Use timeouts for external calls
Gracefully close WebSockets on disconnect
Structured logging for debugging

### N8N Workflow: Voice-AI Orchestrator

The n8n workflow integrates with the FastAPI application via webhooks and handles chat history, transcripts, and meeting scheduling. The workflow is organized as follows:

#### Entry Point: Single Webhook
- **Node**: Webhook
- **Type**: Webhook (POST)
- **Path**: /webhook
- **Behavior**: Accepts all incoming calls from the FastAPI app. Expects JSON with a top-level "route" key set to "1", "2", or "3", plus other fields depending on route.

#### Router: Switch on route
- **Node**: Switch route
- **Type**: Switch
- **Field Checked**: `{{$json["route"]}}`
- **Branches**:
  - Route 1 (== "1") → Fetch History
  - Route 2 (== "2") → Save Transcript
  - Route 3 (== "3") → Book Meeting

#### Route 1: Fetch Prior Chat History
1. **Google Sheets Lookup**
   - **Node**: Lookup Sheet Row
   - **Action**: Finds a row by number (caller's phone)
   - **Returns**: name (if saved), plus any stored summary/transcript columns

2. **Function: Build First Message**
   - **Node**: Build Greeting
   - **Code**:
     ```javascript
     const data = items[0].json;
     const name = data.name;
     const defaultMsg = "Hi, this is Julia speaking. How can I help you today?";
     const firstMessage = name
       ? `Hi, this is Julia speaking. ${name}, how can I help you today?`
       : defaultMsg;
     return [{ json: { firstMessage, callerNumber: data.number } }];
     ```

3. **Respond to Webhook**
   - **Node**: Respond First Message
   - **Type**: Respond to Webhook
   - **Output**:
     ```json
     {
       "firstMessage": "...",
       "callerNumber": "..."
     }
     ```

#### Route 2: Persist Call Transcript & Summary
1. **Webhook (Save Transcript)**
   - Accepts JSON `{ route:"2", number, transcript, summary? }`.

2. **Optional LLM Summarization**
   - **Node**: Summarize Call (OpenAI Chat)
   - **Prompt**: "Summarize this transcript in one sentence: {{$json["transcript"]}}"
   - **Output**: single-sentence summary

3. **Google Sheets Append/Upsert**
   - **Node**: Append Call History
   - **Writes**:
     - number → caller's phone
     - transcript → full call text
     - summary → either the incoming summary or the LLM's

4. **Respond to Webhook**
   - **Node**: Respond OK
   - **Output**: `{ "status":"ok" }`

#### Route 3: Book Meeting
1. **3A. Normalize Incoming Payload**
   - **Function: Format Date & Time**
   - **Node**: Format Date & Time
   - **Reads**:
     ```javascript
     const body = items[0].json.body || items[0].json;
     const { name,email,purpose,datetime } = body.payload;
     ```
   - **Preserves** datetime as a UK-local string ("YYYY-MM-DDTHH:mm:ss")
   - **Computes** an end time one hour later in the same format
   - **Returns**:
     ```json
     {
       "name", "email", "purpose",
       "start":"2025-04-30T16:00:00",
       "end":  "2025-04-30T17:00:00",
       "number": body.number
     }
     ```

2. **3B. Check Original Slot**
   - **Google Calendar Get Events**
   - **Node**: Check Slot
   - **Calendar ID**: (your default)
   - **Time Min**: `{{$node["Format Date & Time"].json.start}}`
   - **Time Max**: `{{$node["Format Date & Time"].json.end}}`
   - **Time Zone**: Europe/London (Advanced)
   - **Max Results**: 1

3. **IF: Is Original Free?**
   - **Node**: If Original Free?
   - **Condition**: `{{$node["Check Slot"].json.length === 0}}`
   - **Keep Input Data**: Enabled

4. **True Branch (Available)**
   - **Google Calendar Create Event (Create Event)**
   - **Summary**: Meeting: `{{$node["Format Date & Time"].json.purpose}}`
   - **Start/End**: as above
   - **Attendee**: `{{$node["Format Date & Time"].json.email}}`
   - **Respond to Webhook (Respond Confirmation)**
   - **Message**: Hi {{name}}, your meeting is confirmed for {{start}}.

5. **False Branch (Booked)**
   - Leads into the "alternative-finder" subflow

#### 3C. Alternative-Finder Subflow
1. **Function: Generate Candidates**
   - **Node**: Generate Candidates
   - **Reads**: startDateStr = items[0].json["Start-Date"]
   - **Parses** as local UK time, eight one-hour offsets
   - **Formats** each as "YYYY-MM-DDTHH:mm:ss" + +01:00 suffix
   - **Returns** 8 items: `{ "start":"...+01:00","end":"...+01:00" }`

2. **SplitInBatches (Loop Candidates)**
   - **Batch Size**: 1

3. **Google Calendar Get Events (Check Each Slot)**
   - **TimeMin**: `{{$json.start}}`
   - **TimeMax**: `{{$json.end}}`
   - **Time Zone**: Europe/London

4. **IF: Is Free?**
   - **Node**: Is Free?
   - **Condition**: `{{$node["Check Each Slot"].json.length === 0}}`
   - **Keep Input Data**: Enabled

5. **True → Build Human Message**
   - **Node**: Build Alternative Message
   - **Code**:
     ```javascript
     const iso = items[0].json["start"];
     const dt  = new Date(iso);
     const friendly = dt.toLocaleString('en-GB',{…}).replace(',', ' at');
     const templates = [
       `I'm sorry, that slot is booked. Would ${friendly} suit you instead?`,
       /* …more variations… */
     ];
     const message = templates[Math.floor(Math.random()*templates.length)];
     return [{ json:{ message }}];
     ```

6. **Respond to Webhook (Respond Alternatives)**
   - **Output**: `{ "message": "{{message from Build Alternative Message}}" }`

7. **False → loops back** to SplitInBatches, testing the next candidate until one is free or all 8 are exhausted.

#### Termination
Both the Respond Confirmation and Respond Alternatives nodes are terminal: once they fire, the workflow stops and sends the HTTP response back to the FastAPI app (and thus to the caller).

#### Data Flow Summary
- Incoming POST → Webhook → Switch route
- Route 1 → Sheets lookup → greeting → Respond
- Route 2 → save transcript/summary → Respond
- Route 3 → normalize times → check slot →
  - Available → create event → Respond
  - Unavailable → generate + test 8 alternates → Respond first free

#### Important Route Numbers
- Route 1: Fetch chat history
- Route 2: Save transcript/summary
- Route 3: Schedule meeting

Endpoints

POST /incoming-call
Input: Twilio webhook form data (e.g. From, To)
Action:
Fetch chat history (route: 1) via N8N
Seed session store
Return TwiML to connect and start media streaming
WS /media-stream
Handshake: Expects initial JSON with sessionId
Stream In: Twilio audio events mapped to OpenAI input.audio
Stream Out: OpenAI response.audio.delta mapped back to Twilio "media" events
Function Calls: Handles Q&A and booking workflows
Example Flow

User calls the number
Twilio sends /incoming-call request; the app returns TwiML
Twilio opens a WebSocket to /media-stream
The caller speaks; audio flows to OpenAI
OpenAI responds (e.g. greeting, answers questions, books meetings)
The caller hears the agent in real time
Testing

Unit Tests:
Mock Twilio form parsing
Mock session store
Mock Pinecone and N8N HTTP calls
Integration Tests:
Simulate Twilio WebSocket audio frames
Mock OpenAI Realtime WS with canned responses
Load Tests:
Use tools like locust or k6 to simulate concurrent calls
Deployment

Dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
Kubernetes / ECS / Compose
Set environment variables via secrets
Health check on /
Monitoring
Expose Prometheus metrics (latency, errors, active sessions)
Alerts on high error rates or stream dropouts
Troubleshooting

No session found
Ensure Twilio passes the correct sessionId
Check logs for session creation entries
Timeouts on N8N or Pinecone
Increase HTTP client timeouts
Verify network connectivity to webhook URL
Latency too high
Confirm use of async HTTP client
Optimize Pinecone queries (index size, chunking)

## Next Steps

1. **Create a `requirements.txt` file**:
   - List all dependencies required for the project (FastAPI, httpx, websockets, python-dotenv, etc.).

2. **Set up a `.env` file**:
   - Create a `.env` file to store environment variables like `OPENAI_API_KEY`, `PINECONE_API_KEY`, `N8N_WEBHOOK_URL`, `REPL_PUBLIC_URL`, and `PORT`.

3. **Implement Pinecone Integration**:
   - Integrate Pinecone to fetch real answers from the knowledge base for the Q&A function.

4. **Implement N8N Integration**:
   - Ensure the meeting scheduling function correctly interacts with N8N to check availability and create events.

5. **Testing**:
   - Set up unit tests for the FastAPI endpoints and WebSocket handlers.
   - Test the integration with Twilio, OpenAI, Pinecone, and N8N.

6. **Error Handling and Logging**:
   - Enhance error handling and logging to make debugging easier.

7. **Deployment**:
   - Prepare for deployment by setting up Docker and ensuring the service can run in a production environment.

